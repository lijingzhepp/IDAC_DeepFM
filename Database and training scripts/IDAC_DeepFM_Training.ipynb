{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bce74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import exp\n",
    "from pandas import cut\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.optimizers import Adam, Adagrad\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "from tensorflow.keras.models import  save_model,load_model\n",
    "from deepctr.layers import custom_objects\n",
    "from deepctr.models import DeepFM\n",
    "from deepctr.feature_column import SparseFeat, DenseFeat, get_feature_names\n",
    "import xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edd6cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Import data\n",
    "data = pd.read_csv('./Data_01032022_Shuffled.csv')\n",
    "print(data)\n",
    "sparse_features = list(data.columns)[9:]\n",
    "dense_features = list(data.columns)[1:9]\n",
    "target = ['column1']\n",
    "\n",
    "print(dense_features)\n",
    "print(sparse_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850d102e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.Label Encoding for sparse features,and do simple Transformation for dense features\n",
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    data[feat] = lbe.fit_transform(data[feat])\n",
    "\n",
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "data[dense_features] = mms.fit_transform(data[dense_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f040441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.Count unique features for each sparse field\n",
    "embedding_list = [4, 5, 6, 7]\n",
    "e = embedding_list[1]\n",
    "\n",
    "fixlen_feature_columns = [SparseFeat(feat, data[feat].max() + 1, embedding_dim=e)\n",
    "                          for feat in sparse_features] + [DenseFeat(feat, 1, ) for feat in dense_features]\n",
    "\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "dnn_feature_columns = fixlen_feature_columns\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a03796a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.Generate input data for model\n",
    "train_and_validation = data.loc[0:47152,:]\n",
    "test = data.loc[47153:52371,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b528c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_list = [list(i for i in range(0,5239)), \n",
    "                   list(i for i in range(5239,10478)), \n",
    "                   list(i for i in range(10478,15717)), \n",
    "                   list(i for i in range(15717,20956)), \n",
    "                   list(i for i in range(20956,26195)), \n",
    "                   list(i for i in range(26195,31434)), \n",
    "                   list(i for i in range(31434,36673)), \n",
    "                   list(i for i in range(36673,41913)), \n",
    "                   list(i for i in range(41913,47153))]\n",
    "train_list = [list(i for i in range(5239,47153)), \n",
    "              list(i for i in range(0,5239))+list(i for i in range(10478,47153)), \n",
    "              list(i for i in range(0,10478))+list(i for i in range(15717,47153)), \n",
    "              list(i for i in range(0,15717))+list(i for i in range(20956,47153)), \n",
    "              list(i for i in range(0,20956))+list(i for i in range(26195,47153)), \n",
    "              list(i for i in range(0,26195))+list(i for i in range(31434,47153)), \n",
    "              list(i for i in range(0,31434))+list(i for i in range(36673,47153)), \n",
    "              list(i for i in range(0,36673))+list(i for i in range(41913,47153)), \n",
    "              list(i for i in range(0,41913))]\n",
    "\n",
    "# 5.Create data storage\n",
    "\n",
    "train_mse_res = []\n",
    "validation_mse_res = []\n",
    "test_mse_res = []\n",
    "\n",
    "train_r2_res = []\n",
    "validation_r2_res = []\n",
    "test_r2_res = []\n",
    "\n",
    "train_mae_res = []\n",
    "validation_mae_res = []\n",
    "test_mae_res = []\n",
    "\n",
    "train_aard_res = []\n",
    "validation_aard_res = []\n",
    "test_aard_res = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7351c100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.Cross-validation\n",
    "dnn_structure_list = [(128, 128), (256, 256), (128, 128, 128),(64, 128, 256),\n",
    "                      (256, 128, 64), (256, 256, 64), (256, 256, 256), (512,256,256),\n",
    "                      (128, 128, 128, 128), (256,256,256,64), (512,512,256), (512,512,512), (512, 512, 256, 64)]\n",
    "\n",
    "learningrate_list = [1e-04, 5e-04, 1e-03, 5e-03, 1e-02]\n",
    "batchsize_list = [64, 128, 256, 512]\n",
    "dropout_list = [0, 1e-02, 5e-02, 1e-01, 2e-01]\n",
    "l2linear_list = [0, 1e-06, 1e-05, 1e-04]\n",
    "l2embedding_list = [0, 1e-06, 1e-05, 1e-04]\n",
    "l2dnn_list = [0, 1e-06, 1e-05, 1e-04]\n",
    "\n",
    "x = dnn_structure_list[7]\n",
    "y = learningrate_list[2]\n",
    "z = batchsize_list[2]\n",
    "a = dropout_list[0]\n",
    "b = l2linear_list[2]\n",
    "c = l2embedding_list[2]\n",
    "d = l2dnn_list[0]\n",
    "\n",
    "for i in range(0,9):\n",
    "    for j in range (0,5):\n",
    "        train = train_and_validation.loc[train_list[i],:]\n",
    "        validation = train_and_validation.loc[validation_list[i],:]\n",
    "        train_model_input = {name: train[name].values for name in feature_names}\n",
    "        validation_model_input = {name: validation[name].values for name in feature_names}\n",
    "        test_model_input = {name: test[name].values for name in feature_names}\n",
    "\n",
    "        # 6.1 Define Model,train,predict and evaluate model\n",
    "        model = DeepFM(linear_feature_columns, dnn_feature_columns, dnn_hidden_units=x, dnn_dropout=a, \n",
    "                       l2_reg_linear=b, l2_reg_embedding=c, l2_reg_dnn=d, task='regression')\n",
    "        \n",
    "        model.compile(Adam(y), \"mse\", metrics=['mse'], )\n",
    "        es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "        history = model.fit(train_model_input, train[target].values,\n",
    "                            batch_size=z, epochs=100, verbose=1, \n",
    "                            validation_data=(validation_model_input, validation[target].values), callbacks=[es])\n",
    "\n",
    "        history_name = 'DeepFM_dnn'+str(x)+'_embedding'+str(e)+'_lr'+str(y)+'_bs'+str(z)+'_drop'+str(a)+'_l2l'+str(b)+'_l2e'+str(c)+'_l2d'+str(d)+'_cv'+ str(i+1)+'_rep'+str(j+1)+'_history.npy'\n",
    "        np.save(history_name, history.history)\n",
    "\n",
    "        filename = 'DeepFM_dnn'+str(x)+'_embedding'+str(e)+'_lr'+str(y)+'_bs'+str(z)+'_drop'+str(a)+'_l2l'+str(b)+'_l2e'+str(c)+'_l2d'+str(d)+'_cv'+ str(i+1)+'_rep'+str(j+1)+'_model.h5'\n",
    "        save_model(model, filename)\n",
    "\n",
    "        train_ans = model.predict(train_model_input, batch_size=z)\n",
    "        validation_ans = model.predict(validation_model_input, batch_size=z)\n",
    "        test_ans = model.predict(test_model_input, batch_size=z)\n",
    "\n",
    "        train_mse_res.append(mean_squared_error(train[target].values, train_ans))\n",
    "        validation_mse_res.append(mean_squared_error(validation[target].values, validation_ans))\n",
    "        test_mse_res.append(mean_squared_error(test[target].values, test_ans))\n",
    "\n",
    "        train_r2_res.append(r2_score(train[target].values, train_ans))\n",
    "        validation_r2_res.append(r2_score(validation[target].values, validation_ans))\n",
    "        test_r2_res.append(r2_score(test[target].values, test_ans))\n",
    "\n",
    "        train_mae_res.append(mean_absolute_error(train[target].values, train_ans))\n",
    "        validation_mae_res.append(mean_absolute_error(validation[target].values, validation_ans))\n",
    "        test_mae_res.append(mean_absolute_error(test[target].values, test_ans))\n",
    "\n",
    "        train_aard_res.append(mean_absolute_percentage_error(exp(train[target].values), exp(train_ans)))\n",
    "        validation_aard_res.append(mean_absolute_percentage_error(exp(validation[target].values), exp(validation_ans)))\n",
    "        test_aard_res.append(mean_absolute_percentage_error(exp(test[target].values), exp(test_ans)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e595d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.Check the results visuaslly\n",
    "print(train_mse_res)\n",
    "print(validation_mse_res)\n",
    "print(test_mse_res)\n",
    "\n",
    "print(train_r2_res)\n",
    "print(validation_r2_res)\n",
    "print(test_r2_res)\n",
    "\n",
    "print(train_mae_res)\n",
    "print(validation_mae_res)\n",
    "print(test_mae_res)\n",
    "\n",
    "print(train_aard_res)\n",
    "print(validation_aard_res)\n",
    "print(test_aard_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce616ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Save the results in xlsx file\n",
    "workbook = xlsxwriter.Workbook('IDAC_DeepFM_Continuous_DNN7_2.xlsx')\n",
    "worksheet = workbook.add_worksheet()\n",
    "row = 0\n",
    "for i in range(0,4):\n",
    "    worksheet.write (row, 0, train_mse_res[i])\n",
    "    worksheet.write (row, 1, validation_mse_res[i])\n",
    "    worksheet.write (row, 2, test_mse_res[i])\n",
    "    worksheet.write (row, 3, train_r2_res[i])\n",
    "    worksheet.write (row, 4, validation_r2_res[i])\n",
    "    worksheet.write (row, 5, test_r2_res[i]) \n",
    "    worksheet.write (row, 6, train_mae_res[i])\n",
    "    worksheet.write (row, 7, validation_mae_res[i])\n",
    "    worksheet.write (row, 8, test_mae_res[i])\n",
    "    worksheet.write (row, 9, train_aard_res[i])\n",
    "    worksheet.write (row, 10, validation_aard_res[i])\n",
    "    worksheet.write (row, 11, test_aard_res[i]) \n",
    "    row += 1\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19aa1b16",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
